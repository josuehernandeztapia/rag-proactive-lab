#!/usr/bin/env python3
"""Pre-calibrate AVI/HASE component weights using proxy scores."""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import Iterable, List, Tuple

import pandas as pd

# Proxy mapping: we derive component scores from coverage/downtime for demonstration.
# In production, replace these with real outputs from AVI voice/55 questions.

def parse_args(argv: Iterable[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Grid search weights for HASE components")
    parser.add_argument(
        "--snapshot",
        type=Path,
        default=Path("data/hase/consumos_snapshot_latest.csv.gz"),
        help="Snapshot per placa with coverage/downtime features",
    )
    parser.add_argument(
        "--labels",
        type=Path,
        default=Path("data/hase/dummy_labels.csv"),
        help="Dummy labels generated by generate_dummy_labels.py",
    )
    parser.add_argument(
        "--noise",
        type=float,
        default=0.1,
        help="Noise factor used when generating dummy labels (for reference)",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("notebooks/hase/precalibration_weights.md"),
        help="Markdown summary output",
    )
    return parser.parse_args(argv)


def roc_auc_score_manual(y_true: List[int], y_score: List[float]) -> float:
    # Manual AUC using ranking method
    paired = sorted(zip(y_score, y_true), key=lambda x: x[0])
    rank = 1
    rank_sum = 0
    n_pos = 0
    n_neg = 0
    for score, label in paired:
        if label == 1:
            rank_sum += rank
            n_pos += 1
        else:
            n_neg += 1
        rank += 1
    if n_pos == 0 or n_neg == 0:
        return 0.5
    auc = (rank_sum - n_pos * (n_pos + 1) / 2) / (n_pos * n_neg)
    return auc


def generate_proxy_scores(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    cov14 = df['coverage_ratio_14d'].clip(0, 1).fillna(0.5)
    cov30 = df['coverage_ratio_30d'].clip(0, 1).fillna(0.5)
    downtime = df['downtime_days_14d'].fillna(0)
    engine = df.get('engine_events', pd.Series(0, index=df.index))

    df['historical_score'] = (1 - cov30) * 1000  # Higher when coverage is low
    df['geographic_score'] = (1 - downtime.clip(0, 1)) * 1000  # Penalize large downtime
    df['voice_score'] = (1 - cov14) * 1000  # Voice proxy: lower coverage = more stress
    df['engine_signal'] = (engine.clip(0, 10) / 10) * 1000  # optional extra signal
    return df


def main(argv: Iterable[str] | None = None) -> int:
    args = parse_args(argv)
    snapshot = pd.read_csv(args.snapshot)
    labels = pd.read_csv(args.labels)

    merged = snapshot.merge(labels[['placa', 'default_flag']], on='placa', how='inner')
    merged = generate_proxy_scores(merged)

    weight_grid: List[Tuple[float, float, float]] = []
    for w_voice in [0.3, 0.4, 0.5, 0.6]:
        for w_hist in [0.2, 0.3, 0.4]:
            w_geo = 1.0 - w_voice - w_hist
            if w_geo <= 0:
                continue
            weight_grid.append((round(w_hist, 2), round(w_geo, 2), round(w_voice, 2)))

    results = []
    for w_hist, w_geo, w_voice in weight_grid:
        scores = (
            merged['historical_score'] * w_hist +
            merged['geographic_score'] * w_geo +
            merged['voice_score'] * w_voice
        )
        auc = roc_auc_score_manual(merged['default_flag'].tolist(), scores.tolist())
        results.append({
            'w_hist': w_hist,
            'w_geo': w_geo,
            'w_voice': w_voice,
            'auc': auc,
        })

    results_df = pd.DataFrame(results).sort_values('auc', ascending=False)
    best = results_df.iloc[0]

    summary_lines = [
        '# Pre-calibración HASE (Dummy Labels)',
        '',
        f"Dataset: {args.snapshot} (+ {len(merged)} filas)",
        f"Labels: {args.labels}",
        '',
        f"Mejor combinación encontrada: histórico={best['w_hist']}, geográfico={best['w_geo']}, voz={best['w_voice']}",
        f"AUC (dummy): {best['auc']:.4f}",
        '',
        'Top 5 combinaciones:',
        results_df.head().to_string(index=False),
        '',
        '_Nota: estos resultados usan datos proxy (coverage/downtime) y etiquetas dummy; reemplazar con datos reales tan pronto como estén disponibles._'
    ]
    args.output.parent.mkdir(parents=True, exist_ok=True)
    args.output.write_text('\n'.join(summary_lines), encoding='utf-8')
    print('\n'.join(summary_lines[:6]))
    return 0


if __name__ == '__main__':
    raise SystemExit(main())
